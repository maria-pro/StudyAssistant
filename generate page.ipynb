{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-05T23:37:57.744363Z",
     "start_time": "2025-02-05T23:37:57.742584Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "import pprint\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n"
   ],
   "id": "9174b615ce37a291",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-05T23:37:58.682012Z",
     "start_time": "2025-02-05T23:37:58.439032Z"
    }
   },
   "cell_type": "code",
   "source": [
    "file_path = (\n",
    "    \"/Volumes/mashenka/delete/layout-parser-paper.pdf\"\n",
    ")\n",
    "\n",
    "loader = PyPDFLoader(file_path)\n",
    "pages = []\n",
    "async for page in loader.alazy_load():\n",
    "    pages.append(page)"
   ],
   "id": "36196a103bde11e4",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-05T23:39:00.423887Z",
     "start_time": "2025-02-05T23:39:00.420877Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "\n",
    "# Load embedding model\n",
    "embedding_model = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "# Example document\n",
    "text = \"ChromaDB is a vector database for AI applications.\"\n",
    "\n",
    "# Generate embeddings\n",
    "embedding = embedding_model.encode(text)\n",
    "\n",
    "print(embedding.shape)  # Output: (384,)\n"
   ],
   "id": "d199d9f659730233",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('LayoutParser: A Uniﬁed Toolkit for Deep\\n'\n",
      " 'Learning Based Document Image Analysis\\n'\n",
      " 'Zejiang Shen1 (\\x00 ), Ruochen Zhang2, Melissa Dell3, Benjamin Charles '\n",
      " 'Germain\\n'\n",
      " 'Lee4, Jacob Carlson3, and Weining Li5\\n'\n",
      " '1 Allen Institute for AI\\n'\n",
      " 'shannons@allenai.org\\n'\n",
      " '2 Brown University\\n'\n",
      " 'ruochen zhang@brown.edu\\n'\n",
      " '3 Harvard University\\n'\n",
      " '{melissadell,jacob carlson}@fas.harvard.edu\\n'\n",
      " '4 University of Washington\\n'\n",
      " 'bcgl@cs.washington.edu\\n'\n",
      " '5 University of Waterloo\\n'\n",
      " 'w422li@uwaterloo.ca\\n'\n",
      " 'Abstract. Recent advances in document image analysis (DIA) have been\\n'\n",
      " 'primarily driven by the application of neural networks. Ideally, research\\n'\n",
      " 'outcomes could be easily deployed in production and extended for further\\n'\n",
      " 'investigation. However, various factors like loosely organized codebases\\n'\n",
      " 'and sophisticated model conﬁgurations complicate the easy reuse of im-\\n'\n",
      " 'portant innovations by a wide audience. Though there have been on-going\\n'\n",
      " 'eﬀorts to improve reusability and simplify deep learning (DL) model\\n'\n",
      " 'development in disciplines like natural language processing and computer\\n'\n",
      " 'vision, none of them are optimized for challenges in the domain of DIA.\\n'\n",
      " 'This represents a major gap in the existing toolkit, as DIA is central to\\n'\n",
      " 'academic research across a wide range of disciplines in the social sciences\\n'\n",
      " 'and humanities. This paper introduces LayoutParser, an open-source\\n'\n",
      " 'library for streamlining the usage of DL in DIA research and applica-\\n'\n",
      " 'tions. The core LayoutParser library comes with a set of simple and\\n'\n",
      " 'intuitive interfaces for applying and customizing DL models for layout de-\\n'\n",
      " 'tection, character recognition, and many other document processing tasks.\\n'\n",
      " 'To promote extensibility, LayoutParser also incorporates a community\\n'\n",
      " 'platform for sharing both pre-trained models and full document digiti-\\n'\n",
      " 'zation pipelines. We demonstrate that LayoutParser is helpful for both\\n'\n",
      " 'lightweight and large-scale digitization pipelines in real-word use cases.\\n'\n",
      " 'The library is publicly available at https://layout-parser.github.io.\\n'\n",
      " 'Keywords: Document Image Analysis · Deep Learning · Layout Analysis\\n'\n",
      " '· Character Recognition · Open Source library · Toolkit.\\n'\n",
      " '1 Introduction\\n'\n",
      " 'Deep Learning(DL)-based approaches are the state-of-the-art for a wide range '\n",
      " 'of\\n'\n",
      " 'document image analysis (DIA) tasks including document image classiﬁcation '\n",
      " '[11,\\n'\n",
      " 'arXiv:2103.15348v2  [cs.CV]  21 Jun 2021')\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-02-05T23:37:10.615139Z",
     "start_time": "2025-02-05T23:37:10.607999Z"
    }
   },
   "source": [
    "import fitz\n",
    "import matplotlib.patches as patches\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "def plot_pdf_with_boxes(pdf_page, segments):\n",
    "    pix = pdf_page.get_pixmap()\n",
    "    pil_image = Image.frombytes(\"RGB\", [pix.width, pix.height], pix.samples)\n",
    "\n",
    "    fig, ax = plt.subplots(1, figsize=(10, 10))\n",
    "    ax.imshow(pil_image)\n",
    "    categories = set()\n",
    "    category_to_color = {\n",
    "        \"Title\": \"orchid\",\n",
    "        \"Image\": \"forestgreen\",\n",
    "        \"Table\": \"tomato\",\n",
    "    }\n",
    "    for segment in segments:\n",
    "        points = segment[\"coordinates\"][\"points\"]\n",
    "        layout_width = segment[\"coordinates\"][\"layout_width\"]\n",
    "        layout_height = segment[\"coordinates\"][\"layout_height\"]\n",
    "        scaled_points = [\n",
    "            (x * pix.width / layout_width, y * pix.height / layout_height)\n",
    "            for x, y in points\n",
    "        ]\n",
    "        box_color = category_to_color.get(segment[\"category\"], \"deepskyblue\")\n",
    "        categories.add(segment[\"category\"])\n",
    "        rect = patches.Polygon(\n",
    "            scaled_points, linewidth=1, edgecolor=box_color, facecolor=\"none\"\n",
    "        )\n",
    "        ax.add_patch(rect)\n",
    "\n",
    "    # Make legend\n",
    "    legend_handles = [patches.Patch(color=\"deepskyblue\", label=\"Text\")]\n",
    "    for category in [\"Title\", \"Image\", \"Table\"]:\n",
    "        if category in categories:\n",
    "            legend_handles.append(\n",
    "                patches.Patch(color=category_to_color[category], label=category)\n",
    "            )\n",
    "    ax.axis(\"off\")\n",
    "    ax.legend(handles=legend_handles, loc=\"upper right\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def render_page(doc_list: list, page_number: int, print_text=True) -> None:\n",
    "    pdf_page = fitz.open(file_path).load_page(page_number - 1)\n",
    "    page_docs = [\n",
    "        doc for doc in doc_list if doc.metadata.get(\"page_number\") == page_number\n",
    "    ]\n",
    "    segments = [doc.metadata for doc in page_docs]\n",
    "    plot_pdf_with_boxes(pdf_page, segments)\n",
    "    if print_text:\n",
    "        for doc in page_docs:\n",
    "            print(f\"{doc.page_content}\\n\")"
   ],
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-05T23:37:12.615059Z",
     "start_time": "2025-02-05T23:37:12.604178Z"
    }
   },
   "cell_type": "code",
   "source": "render_page(docs, 5)",
   "id": "8b0253aabdbe1889",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'docs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[13], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m render_page(\u001B[43mdocs\u001B[49m, \u001B[38;5;241m5\u001B[39m)\n",
      "\u001B[0;31mNameError\u001B[0m: name 'docs' is not defined"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "207662dd418678c9"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
